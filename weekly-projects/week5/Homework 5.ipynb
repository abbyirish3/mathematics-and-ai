{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e918709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 5 (due 07/30/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b7099",
   "metadata": {},
   "source": [
    "# SVM and Kernels\n",
    "\n",
    "### Objective\n",
    "Through this project, you will learn to use nonlinear kernels to improve a support vector classifier. The toy examples within this project aim to guide you as you build your intuition for the decision boundaries that can be generated via different kernels.\n",
    "\n",
    "This project is structured as follows:\n",
    "#### Part 1: Binary classification of synthetic data\n",
    "1.1. Generate and explore synthetic data\n",
    "\n",
    "1.2. SVM with nonlinear kernels\n",
    "#### Part 2: US Flags\n",
    "2.1. Load and explore flags data\n",
    "\n",
    "2.2. SVMs for flag pixel data\n",
    "\n",
    "2.3. Comparison to decision trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.datasets import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# you may need to install the PIL in your environment\n",
    "# for installation in mamba environment type \"mamba install pillow -c conda-forge\" in your miniforge prompt\n",
    "# for installation in conda environment type \"conda install pillow -c conda-forge\" in your conda prompt or anaconda prompt\n",
    "# for installation via pip type \"pip install pillow\" in your terminal\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b2d94",
   "metadata": {},
   "source": [
    "## Part 1: Binary classification of synthetic data\n",
    "\n",
    "### Part 1.1: Generate and explore synthetic data\n",
    "The next cell defines the function `generate_dataset`, which you can use to generate synthetic (i.e., computer generated) data sets for binary classification. It includes eight different methods for data-set generation. \n",
    "1. Try out each method and visualize the resulting data set. For the 'swiss' and 'scurve' data sets, try out two different values of the keyword argument `splits`.\n",
    "2. Comment on WHETHER and WHY you anticipate this data set to be relatively easy or relatively hard to classify with a linear classifier.\n",
    "3. Comment on WHETHER and WHY you anticipate this data set to be relatively easy or relatively hard to classify with a nonlinear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0371627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an array of real numbers into an array of 0s and 1s\n",
    "def binarize(arr, split=10):\n",
    "    # Calculate the decile thresholds\n",
    "    percentiles = int(np.ceil(100/split))\n",
    "    split_points = np.arange(0, 100+percentiles, percentiles)\n",
    "    split_points[split_points>100] = 100\n",
    "    deciles = np.percentile(arr, split_points)\n",
    "    \n",
    "    # Create a new array to hold the modified values\n",
    "    modified_arr = np.zeros_like(arr)\n",
    "    \n",
    "    # Iterate through each decile range and set values accordingly\n",
    "    for i in range(split):\n",
    "        print(i)\n",
    "        if i == split-1:\n",
    "            if i % 2 == 0:\n",
    "                # Set values in even deciles to 0\n",
    "                modified_arr[(arr >= deciles[i])] = 0\n",
    "            else:\n",
    "                # Set values in odd deciles to 1\n",
    "                modified_arr[(arr >= deciles[i])] = 1\n",
    "        else:        \n",
    "            if i % 2 == 0:\n",
    "                # Set values in even deciles to 0\n",
    "                modified_arr[(arr >= deciles[i]) & (arr < deciles[i + 1])] = 0\n",
    "            else:\n",
    "                # Set values in odd deciles to 1\n",
    "                modified_arr[(arr >= deciles[i]) & (arr < deciles[i + 1])] = 1\n",
    "    \n",
    "    return modified_arr\n",
    "\n",
    "# Function to generate datasets\n",
    "def generate_dataset(dataset_type, n_samples=300, noise=0.1, split=10, random_state=0):\n",
    "    if dataset_type == 'linearly_separable':\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=2, n_redundant=0, n_informative=2,\n",
    "                                   random_state=random_state, n_clusters_per_class=1)\n",
    "    elif dataset_type == 'blobs':\n",
    "        X, y = make_blobs(n_samples=[n_samples//2, n_samples//2], random_state=random_state, cluster_std=noise)\n",
    "    elif dataset_type == 'quantiles':\n",
    "        X, y = make_gaussian_quantiles(n_samples=n_samples, n_classes=2, cov=noise, random_state=random_state)\n",
    "    elif dataset_type == 'moons':\n",
    "        X, y = make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
    "    elif dataset_type == 'circles':\n",
    "        X, y = make_circles(n_samples=n_samples, noise=noise, factor=0.5, random_state=random_state)\n",
    "    elif dataset_type == 'unstructured':\n",
    "        X, y = np.random.random(size=(n_samples, 2)), np.random.randint(0,2, size=(n_samples))\n",
    "    elif dataset_type == 'swiss':\n",
    "        X, y = make_swiss_roll(n_samples=n_samples, noise=noise, random_state=random_state)\n",
    "        X=np.array([X[:,0],X[:,2]]).T\n",
    "        y = binarize(y, split=split)\n",
    "    elif dataset_type == 'scurve':\n",
    "        X, y = make_s_curve(n_samples=n_samples, noise=noise, random_state=random_state)\n",
    "        X=np.array([X[:,0],X[:,2]]).T\n",
    "        y = binarize(y, split=split)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset type\")\n",
    "    \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate and visualize data blobs\n",
    "# datasets = ['linearly_separable', 'blobs', 'quantiles', 'unstructured', 'moons', 'circles', 'unstructured', 'swiss', 'scurve']\n",
    "\n",
    "def get_color(val):\n",
    "    if val == 1:\n",
    "        return 'blue'\n",
    "    if val == 0:\n",
    "        return 'red'\n",
    "    \n",
    "# for dataset in datasets:\n",
    "#     X, y = generate_dataset(dataset)\n",
    "\n",
    "#     X_cols = X[:, 0]\n",
    "#     y_cols = X[:, 1]\n",
    "\n",
    "#     for i in range(len(X_cols) - 1):\n",
    "#         plt.plot(X_cols[i], y_cols[i], marker = 'o', color = get_color(y[i]))\n",
    "                 \n",
    "#     print(dataset)\n",
    "#     plt.show()\n",
    "\n",
    "# Function to plot datasets\n",
    "def plot_dataset(X, y, title):\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.plot(X[y == 0][:, 0], X[y == 0][:, 1], 'ro', label='Class 0')\n",
    "    plt.plot(X[y == 1][:, 0], X[y == 1][:, 1], 'bo', label='Class 1')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize datasets\n",
    "dataset_types = ['linearly_separable', 'blobs', 'quantiles', 'moons', 'circles', 'unstructured', 'swiss', 'scurve']\n",
    "for dataset_type in dataset_types:\n",
    "    X, y = generate_dataset(dataset_type)\n",
    "    plot_dataset(X, y, dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe629c",
   "metadata": {},
   "source": [
    "I anticipate that the linearly seperable data set should be fairly easy to classify with a linear classifier since the data points are linearly seperable. With a nonlinear classifier, it would also likely perform well since the data set is not very complex, although this type of classifier is unnecessary here.\n",
    "\n",
    "I anticipate that the blobs should be fairly easy to classify with a linear classifier since the blobs are very well separated. A nonlinear classifier again would perform well since the blobs are well separated but would not be necessary for this type of data.\n",
    "\n",
    "I anticipate that the quantiles data set would be more challenging for a linear classifier because the data points are more intermixed and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize unstructured data\n",
    "'''ADD SOME CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37602a2d",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3080bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize circles data set\n",
    "'''ADD SOME CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f821f",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e532eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize Gaussian quantiles\n",
    "'''ADD SOME CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb66d6",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ef8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize linearly separable data\n",
    "'''ADD SOME CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154ab5a",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22355bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize moons data set\n",
    "'''ADD SOME CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434dbaf5",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82662d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize swiss role with 2 split sets\n",
    "X, y = generate_dataset('swiss', split=2)\n",
    "    \n",
    "x_cols = X[:,0]\n",
    "y_cols = X[:,1]\n",
    "for i in range (len(x_cols)-1):\n",
    "        \n",
    "    plt.plot(x_cols[i], y_cols[i], marker='o', color=get_color(y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817b7a1",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize S curve with 2 split sets\n",
    "X, y = generate_dataset('scurve', split=2)\n",
    "    \n",
    "x_cols = X[:,0]\n",
    "y_cols = X[:,1]\n",
    "for i in range (len(x_cols)-1):\n",
    "        \n",
    "    plt.plot(x_cols[i], y_cols[i], marker='o', color=get_color(y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99672f28",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2987396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize swiss role with 10 split sets\n",
    "X, y = generate_dataset('swiss', split=10)\n",
    "    \n",
    "x_cols = X[:,0]\n",
    "y_cols = X[:,1]\n",
    "for i in range (len(x_cols)-1):\n",
    "        \n",
    "    plt.plot(x_cols[i], y_cols[i], marker='o', color=get_color(y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3fbca",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize S curve with 10 split sets\n",
    "X, y = generate_dataset('scurve', split=10)\n",
    "    \n",
    "x_cols = X[:,0]\n",
    "y_cols = X[:,1]\n",
    "for i in range (len(x_cols)-1):\n",
    "        \n",
    "    plt.plot(x_cols[i], y_cols[i], marker='o', color=get_color(y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db61e0f",
   "metadata": {},
   "source": [
    "I anticipate that this data set [ADD SOME TEXT HERE]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ec602",
   "metadata": {},
   "source": [
    "### Part 1.2: SVM with nonlinear kernels\n",
    "\n",
    "The next cell defines the function `kernel_comparison`, which you can use to visually compare the decision boundaries generated by SVMs with different kernels. \n",
    "\n",
    "1. The kernel comparison currently produces only visual results. Add code to the function so that it also outputs train and test accuracy of the different SVMs. (Note: Think carefully about where the right place in the code is to do a train-test split.)\n",
    "2. Run the kernel comparison for the data sets from Part 1.1. Do the results confirm or contradict your expectations that you formulated in Part 1.1.? Did any of the results surprise you?\n",
    "3. Consult sklearn's documentation to learn how the keyword arguments `degree` and `gamma` affect your classifier. Try out a few different values of these parameters. How and what can one infer from the shape of the decision boundary about the classifier's `degree` or `gamma`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d069234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_comparison(X, y, support_vectors=True, tight_box=False, if_flag=False):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,3))\n",
    "    \n",
    "    for ikernel, kernel in enumerate(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "        print(kernel)\n",
    "        # Train the SVC\n",
    "        clf = SVC(kernel=kernel, degree=3, gamma=3).fit(X, y)\n",
    "        prediction = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        print(accuracy)\n",
    "    \n",
    "        # Settings for plotting\n",
    "        ax = plt.subplot(1,4,1+ikernel)\n",
    "        #x_min, x_max, y_min, y_max = -3, 3, -3, 3\n",
    "        #ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    \n",
    "        # Plot decision boundary and margins\n",
    "        common_params = {\"estimator\": clf, \"X\": X, \"ax\": ax}\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            **common_params,\n",
    "            response_method=\"predict\",\n",
    "            plot_method=\"pcolormesh\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            **common_params,\n",
    "            response_method=\"decision_function\",\n",
    "            plot_method=\"contour\",\n",
    "            levels=[-1, 0, 1],\n",
    "            colors=[\"k\", \"k\", \"k\"],\n",
    "            linestyles=[\"--\", \"-\", \"--\"],\n",
    "        )\n",
    "    \n",
    "        if support_vectors:\n",
    "            # Plot bigger circles around samples that serve as support vectors\n",
    "            ax.scatter(\n",
    "                clf.support_vectors_[:, 0],\n",
    "                clf.support_vectors_[:, 1],\n",
    "                s=150,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"k\",\n",
    "            )\n",
    "    \n",
    "        # Plot samples by color and add legend\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, s=30, edgecolors=\"k\")\n",
    "        ax.set_title(kernel)\n",
    "        ax.axis('off')\n",
    "        if tight_box:\n",
    "            ax.set_xlim([X[:, 0].min(), X[:, 0].max()])\n",
    "            ax.set_ylim([X[:, 1].min(), X[:, 1].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e084580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results of kernel comparison for data sets from part 1\n",
    "for dataset_type in dataset_types:\n",
    "    X, y = generate_dataset(dataset_type)\n",
    "\n",
    "    print(f\"Dataset: {dataset_type}\")\n",
    "    kernel_comparison(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc154e",
   "metadata": {},
   "source": [
    "To summarize the results of the kernel comparison, [ADD SOME TEXT HERE]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine effect of degree and gamma keyword\n",
    "degrees = [2, 3]\n",
    "gammas = [0.1, 1]\n",
    "\n",
    "for degree in degrees:\n",
    "    for gamma in gammas:\n",
    "        print(f\"Experimenting with degree={degree} and gamma={gamma}\")\n",
    "        for dataset_type in dataset_types:\n",
    "            X, y = generate_dataset(dataset_type)\n",
    "            print(f\"Dataset: {dataset_type}\")\n",
    "            kernel_comparison(X, y, degree, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad9be1",
   "metadata": {},
   "source": [
    "The `degree` argument affects [ADD NAME OF DATA GENERATION METHOD]. It changes the model by [ADD SOME TEXT HERE]. This affects the model's bias-variance tradeoff by [ADD SOME TEXT HERE]. \n",
    "\n",
    "As one increases the `degree`, the decision boundary [ADD SOME TEXT HERE]. \n",
    "\n",
    "The `gamma` argument affects [ADD NAME OF DATA GENERATION METHOD]. It changes the model by [ADD SOME TEXT HERE]. This affects the model's bias-variance tradeoff by [ADD SOME TEXT HERE]. \n",
    "\n",
    "As one increases `gamma`, the decision boundary of [ADD SOME TEXT HERE]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce9c37",
   "metadata": {},
   "source": [
    "## Part 2: US Flags\n",
    "\n",
    "### Part 2.1: Load and explore flags data\n",
    "The function `load_images` loads the image data from the flags folder and turns each image into a binary (i.e., black and white) array.\n",
    "\n",
    "1. Load the flags data.\n",
    "2. Display four flags of your choice in a figure. Use the `matplotlib` commands `subplot` and `imshow` to create a figure with 2x2 flags. Consult the `matplotlib` documentation to find a way set the aspect ratio of your displayed flags to match their original aspect ratio. Update your code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = Image.open(img_path).convert('L')  # Convert image to black and white\n",
    "            img = np.array(img)//(256/2) # Convert to BW\n",
    "            images.append(img)\n",
    "            labels.append(filename.split('.')[0])  # Extract the state code as label\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display four black-and-white flags in a 2x2 grid\n",
    "\n",
    "# load images and labels from the flags folder\n",
    "images, labels = load_images('flags')\n",
    "\n",
    "# make state abbreviations uppercase\n",
    "upper_labels = []\n",
    "for label in labels:\n",
    "    label = label.upper()\n",
    "    upper_labels.append(label)\n",
    "\n",
    "# Select four images of your choice (here selecting the first four images for demonstration)\n",
    "selected_images = images[:4]\n",
    "selected_labels = upper_labels[:4]\n",
    "\n",
    "# Display the selected images in a 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(selected_images[i], cmap='gray') # do i need aspect='auto' parameter??\n",
    "    ax.set_title(selected_labels[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182c4ec",
   "metadata": {},
   "source": [
    "### Part 2.2: SVMs for flag pixel data\n",
    "The function `sample_pixels` samples a pixel from a given image uniformly at random. \n",
    "\n",
    "1. Use the `sample_pixels`  function to generate synthetic data sets of pixels from for a flag image.\n",
    "2. Update the `kernel_comparison` function so that if `if_flag` is `True` the decision boundaries are plotted in a 2x2 grid of subplots with plot ranges matching the height and width of the flags.\n",
    "3. Show the results of the kernel comparison for the four flags that your previously selected. Use the highest values of `degree` and `gamma` that still run *reasonably fast* on your laptop.\n",
    "4. Adjust your code so that you can run the quantitative part (i.e., the calculation of train and test accuracy) without plotting the decision boundaries. Run the adjusted code on all flags to indentify for each kernel the flags that yield to best easiest-to-classify and hardest-to-classify data sets. Test how the number of of pixels sampled affects your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d22c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pixels(image, num_samples=100):\n",
    "    pixel_data = []\n",
    "    pixel_labels = []\n",
    "    height, width = image.shape\n",
    "    for _ in range(num_samples):\n",
    "        x1 = random.randint(0, width - 1)\n",
    "        x2 = random.randint(0, height - 1)\n",
    "        pixel_data.append([x1/width-0.5, x2/width-0.5])\n",
    "        pixel_labels.append(image[x2,x1])\n",
    "    return np.array(pixel_data), np.array(pixel_labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual kernel comparison for selected flags\n",
    "def kernel_comparison(X, y, support_vectors=True, tight_box=False, if_flag=False):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,3))\n",
    "    \n",
    "    for ikernel, kernel in enumerate(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "        # Train the SVC\n",
    "        clf = SVC(kernel=kernel, degree=3, gamma=3).fit(X, y)\n",
    "        prediction = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        print(f\"{kernel} Test Accuracy: {accuracy}\")\n",
    "    \n",
    "        # Settings for plotting\n",
    "        ax = plt.subplot(1,4,1+ikernel)\n",
    "        if if_flag:\n",
    "            x_min, x_max, y_min, y_max = -3, 3, -3, 3\n",
    "            ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    \n",
    "        # Plot decision boundary and margins\n",
    "        common_params = {\"estimator\": clf, \"X\": X, \"ax\": ax}\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            **common_params,\n",
    "            response_method=\"predict\",\n",
    "            plot_method=\"pcolormesh\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            **common_params,\n",
    "            response_method=\"decision_function\",\n",
    "            plot_method=\"contour\",\n",
    "            levels=[-1, 0, 1],\n",
    "            colors=[\"k\", \"k\", \"k\"],\n",
    "            linestyles=[\"--\", \"-\", \"--\"],\n",
    "        )\n",
    "    \n",
    "        if support_vectors:\n",
    "            # Plot bigger circles around samples that serve as support vectors\n",
    "            ax.scatter(\n",
    "                clf.support_vectors_[:, 0],\n",
    "                clf.support_vectors_[:, 1],\n",
    "                s=150,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"k\",\n",
    "            )\n",
    "    \n",
    "        # Plot samples by color and add legend\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, s=30, edgecolors=\"k\")\n",
    "        ax.set_title(kernel)\n",
    "        ax.axis('off')\n",
    "        if tight_box:\n",
    "            ax.set_xlim([X[:, 0].min(), X[:, 0].max()])\n",
    "            ax.set_ylim([X[:, 1].min(), X[:, 1].max()])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-visual kernel comparison for all flags\n",
    "for img, label in zip(images, upper_labels):\n",
    "    X, y = sample_pixels(img)\n",
    "    print(f\"Flag: {label}\")\n",
    "    kernel_comparison(X, y, support_vectors=True, tight_box=True, if_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e055c6",
   "metadata": {},
   "source": [
    "For these experiments, I set `num_samples` to [ADD NUMBER HERE] because the results of the experiments seem to be the most stable for this number of sampled pixels.\n",
    "\n",
    "The linear kernel performed best (i.e., highest test accuracy) on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]\n",
    "\n",
    "It performed worst on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5174bc",
   "metadata": {},
   "source": [
    "The polynomial kernel performed best on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]\n",
    "\n",
    "It performed worst on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d170b9a",
   "metadata": {},
   "source": [
    "The radial-basis function kernel performed best on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]\n",
    "\n",
    "It performed worst on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3e040",
   "metadata": {},
   "source": [
    "The sigmoid kernel performed best on the flags of the following three states: \n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]\n",
    "\n",
    "It performed worst on the flags of the following three states:\n",
    "\n",
    "[ADD TOP THREE STATE NAMES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b366061",
   "metadata": {},
   "source": [
    "### Part 2.3: Comparison to decision trees\n",
    "Decision trees and SVMs yield substantially different decision boundaries.\n",
    "\n",
    "1. An arbitrarily complex decision tree would be able to achieve perfect training accuracy on any data set. Explain why.\n",
    "2. For a very large data set of flag pixels, an arbitrarily complex decision tree is likely to achieve (almost) perfect test accuracy as well. Explain why.\n",
    "3. Select four flags for which you anticipate a *simple* decision tree to outperform all your SVMs. Write code that fits a decision tree to a flag pixel data set. Use your code to check your hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279ea4e",
   "metadata": {},
   "source": [
    "An arbitrarily complex decision tree would be able to achieve perfect training accuracy on any data set, because [ADD SOME TEXT HERE].\n",
    "\n",
    "For a very large data set of flag pixels, an arbitrarily complex decision tree is likely to achieve (almost) perfect test accuracy because [ADD SOME TEXT HERE].\n",
    "\n",
    "A simple decision tree is likely to perform well on the sampled pixel data of the flags of [ADD NAMES OF AT LEAST FOUR US STATES HERE]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of SVM and decision tree performance on sampled pixel data for four flags\n",
    "\n",
    "'''ADD CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681d68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
